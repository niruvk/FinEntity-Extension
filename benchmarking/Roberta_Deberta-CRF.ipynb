{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":36727,"status":"ok","timestamp":1746345242906,"user":{"displayName":"Niranjan Vijaya Krishnan","userId":"18319157086641608251"},"user_tz":240},"id":"iUgqPilfbtY-","outputId":"27d02192-4e6a-4a24-db45-3024b901f39a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'FinEntity'...\n","remote: Enumerating objects: 118, done.\u001b[K\n","remote: Total 118 (delta 0), reused 0 (delta 0), pack-reused 118 (from 1)\u001b[K\n","Receiving objects: 100% (118/118), 28.24 MiB | 8.70 MiB/s, done.\n","Resolving deltas: 100% (39/39), done.\n","Updating files: 100% (58/58), done.\n","Downloading model_bert_crf (439 MB)\n","Error downloading object: model_bert_crf (24132d8): Smudge error: Error downloading model_bert_crf (24132d85e1ad90e91d9688e5ddaf6f520396644386817fa2f877f21a58ea84fe): batch response: This repository exceeded its LFS budget. The account responsible for the budget should increase it to restore access.\n","\n","Errors logged to /content/FinEntity/.git/lfs/logs/20250504T075331.905138192.log\n","Use `git lfs logs last` to view the log.\n","error: external filter 'git-lfs filter-process' failed\n","fatal: model_bert_crf: smudge filter lfs failed\n","warning: Clone succeeded, but checkout failed.\n","You can inspect what was checked out with 'git status'\n","and retry with 'git restore --source=HEAD :/'\n","\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n","Collecting sequence-aligner\n","  Downloading sequence_aligner-0.0.2.tar.gz (5.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting evaluate\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Collecting datasets>=2.0.0 (from evaluate)\n","  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n","Collecting dill (from evaluate)\n","  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n","Collecting xxhash (from evaluate)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from evaluate)\n","  Downloading multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n","Collecting dill (from evaluate)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Collecting multiprocess (from evaluate)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n","Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.5.1-py3-none-any.whl (491 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: sequence-aligner\n","  Building wheel for sequence-aligner (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sequence-aligner: filename=sequence_aligner-0.0.2-py3-none-any.whl size=7152 sha256=a37afb54e3d5523cc68cde5ddf2b1eeae338f1d7d82b6053892d37e49c244d7d\n","  Stored in directory: /root/.cache/pip/wheels/56/5a/0f/e32d263a93541ae75ce1f9fc38a77d218cf7714152bb2de9aa\n","Successfully built sequence-aligner\n","Installing collected packages: sequence-aligner, xxhash, fsspec, dill, multiprocess, datasets, evaluate\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.2\n","    Uninstalling fsspec-2025.3.2:\n","      Successfully uninstalled fsspec-2025.3.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.5.1 dill-0.3.8 evaluate-0.4.3 fsspec-2025.3.0 multiprocess-0.70.16 sequence-aligner-0.0.2 xxhash-3.5.0\n","Collecting pytorch-crf\n","  Downloading pytorch_crf-0.7.2-py3-none-any.whl.metadata (2.4 kB)\n","Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n","Installing collected packages: pytorch-crf\n","Successfully installed pytorch-crf-0.7.2\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (2.0.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.6.1)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=d3ed923bbd6072c85fb17b23c381158b87cbe71d3e98c197dd08c2d2a558ea1f\n","  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"]}],"source":["# ======================= SETUP =======================\n","!git clone https://github.com/yixuantt/FinEntity.git\n","!pip install transformers sequence-aligner evaluate\n","!pip install pytorch-crf\n","!pip install seqeval\n","\n","import json\n","import warnings\n","import numpy as np\n","import torch\n","from torch.utils.data import DataLoader, random_split\n","from torch import cuda\n","from transformers import (\n","    AutoTokenizer, AutoModelForTokenClassification,\n","    get_linear_schedule_with_warmup\n",")\n","from torch.optim import AdamW\n","from FinEntity.sequence_aligner.labelset import LabelSet\n","from FinEntity.sequence_aligner.dataset import TrainingDataset\n","from FinEntity.sequence_aligner.containers import TraingingBatch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cT1oPltJcD94"},"outputs":[],"source":["# ======================= LOAD DATA =======================\n","raw = json.load(open('FinEntity/data/FinEntity.json'))"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"7k0smMmfcHwN"},"outputs":[],"source":["# ======================= CHOOSE MODEL =======================\n","# Choose ONE of the following model names:\n","# model_name = \"bert-base-cased\"\n","model_name = \"roberta-base\"\n","# model_name = \"microsoft/deberta-base\"\n","\n","# model_name = \"microsoft/deberta-base\"  # <<<<<<<<<<<< switch here\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":189,"status":"ok","timestamp":1746348455558,"user":{"displayName":"Niranjan Vijaya Krishnan","userId":"18319157086641608251"},"user_tz":240},"id":"LQRKNb2acNo_","outputId":"cf8ddb0b-2b6b-4d89-8198-c6152d74b6f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Label mapping: {0: 'O', 1: 'B-Neutral', 2: 'I-Neutral', 3: 'L-Neutral', 4: 'U-Neutral', 5: 'B-Positive', 6: 'I-Positive', 7: 'L-Positive', 8: 'U-Positive', 9: 'B-Negative', 10: 'I-Negative', 11: 'L-Negative', 12: 'U-Negative'}\n"]}],"source":["# ======================= SETUP LABELS =======================\n","label_set = LabelSet(labels=[\"Neutral\", \"Positive\", \"Negative\"])\n","print(\"Label mapping:\", label_set.ids_to_label)\n","dataset = TrainingDataset(\n","    data=raw,\n","    tokenizer=tokenizer,\n","    label_set=label_set,\n","    tokens_per_batch=128\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BaK2Kzr5cTEQ"},"outputs":[],"source":["# ======================= TRAIN/VAL SPLIT =======================\n","train_size = int(0.8 * len(dataset))\n","validate_size = len(dataset) - train_size\n","train_dataset, validate_dataset = random_split(dataset, [train_size, validate_size])\n","\n","def collate_fn(batch):\n","    batch_data = TraingingBatch(batch)\n","    batch_data.labels[batch_data.labels == -100] = 0  # Replace invalid label\n","    return batch_data\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, collate_fn=collate_fn, shuffle=True)\n","val_loader = DataLoader(validate_dataset, batch_size=16, collate_fn=collate_fn, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4reFQnBcFr5D"},"outputs":[],"source":["# Define model with CRF\n","from torch import nn\n","from transformers import AutoModel\n","from torchcrf import CRF\n","\n","class TokenClassifierWithCRF(nn.Module):\n","    def __init__(self, model_name, num_labels):\n","        super().__init__()\n","        self.bert = AutoModel.from_pretrained(model_name)\n","        self.dropout = nn.Dropout(0.1)\n","        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n","        self.crf = CRF(num_labels, batch_first=True)\n","\n","    def forward(self, input_ids, attention_mask, labels=None):\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        sequence_output = self.dropout(outputs.last_hidden_state)\n","        emissions = self.classifier(sequence_output)  # [batch_size, seq_len, num_labels]\n","\n","        if labels is not None:\n","            # CRF expects [B, T, num_labels] and [B, T] for mask and labels\n","            loss = -self.crf(emissions, labels, mask=attention_mask.bool(), reduction='mean')\n","            return loss\n","        else:\n","            # For prediction, return the best path\n","            prediction = self.crf.decode(emissions, mask=attention_mask.bool())\n","            return prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":559,"status":"ok","timestamp":1746348464790,"user":{"displayName":"Niranjan Vijaya Krishnan","userId":"18319157086641608251"},"user_tz":240},"id":"gp_aHwU_cUXv","outputId":"eaeb3a89-afdf-4093-d6d0-33297813ddd3"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["TokenClassifierWithCRF(\n","  (bert): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=13, bias=True)\n","  (crf): CRF(num_tags=13)\n",")"]},"metadata":{},"execution_count":34}],"source":["# ======================= MODEL INIT =======================\n","model = TokenClassifierWithCRF(\n","    model_name,\n","    num_labels=len(label_set.ids_to_label.values())\n",")\n","\n","device = 'cuda:0' if cuda.is_available() else 'cpu'\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m5wuGS9Zcawi"},"outputs":[],"source":["# ======================= TRAINING CONFIG =======================\n","t_total = len(train_loader) * 10  # 3 epochs\n","weight_decay = 0.01\n","learning_rate = 3e-5\n","warmup_ratio = 0.1\n","\n","no_decay = [\"bias\", \"LayerNorm.weight\"]\n","optimizer_grouped_parameters = [\n","    {\n","        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","        \"weight_decay\": weight_decay,\n","    },\n","    {\n","        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","        \"weight_decay\": 0.0,\n","    },\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=1e-6)\n","warmup_steps = int(t_total * warmup_ratio)\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qzpc1AYpco6a"},"outputs":[],"source":["from seqeval.metrics import classification_report\n","from seqeval.scheme import BILOU\n","from tqdm import tqdm\n","\n","def train_epoch(e, model, data_loader, optimizer, scheduler, device):\n","    model.train()\n","    total_loss = 0.0\n","    for step, d in enumerate(data_loader):\n","        input_ids = d[\"input_ids\"].to(device)\n","        attention_mask = d[\"attention_masks\"].to(device)\n","        labels = d[\"labels\"].to(device)\n","\n","        loss = model(input_ids, attention_mask, labels)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","        total_loss += loss.item()\n","    print(f\"Epoch {e+1}: Train loss = {total_loss / len(data_loader):.4f}\")\n","\n","def valid_epoch(e, model, data_loader, device, label_set):\n","    model.eval()\n","    all_preds, all_labels = [], []\n","\n","    for batch in tqdm(data_loader, desc=f\"Validation Epoch {e+1}\"):\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_masks'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        with torch.no_grad():\n","            predictions = model(input_ids=input_ids, attention_mask=attention_mask)  # returns List[List[int]]\n","\n","        # Convert labels to CPU and to list of lists (unpad)\n","        true_labels = labels.cpu().tolist()\n","        attention_mask_cpu = attention_mask.cpu().tolist()\n","\n","        for preds, label_ids, mask in zip(predictions, true_labels, attention_mask_cpu):\n","            true = [label_set.ids_to_label[i] for i, m in zip(label_ids, mask) if m == 1]\n","            pred = [label_set.ids_to_label[i] for i in preds]  # preds are already masked by CRF\n","            all_labels.append(true)\n","            all_preds.append(pred)\n","\n","    print(\"\\nValidation Report:\")\n","    print(classification_report(all_labels, all_preds, mode='strict', scheme=BILOU))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05aJUKnFcp_5","executionInfo":{"status":"ok","timestamp":1746348827237,"user_tz":240,"elapsed":236000,"user":{"displayName":"Niranjan Vijaya Krishnan","userId":"18319157086641608251"}},"outputId":"30bb3fd9-1ec5-4487-a994-bc168733a07f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","===== EPOCH 1 =====\n","Epoch 1: Train loss = 12.3043\n"]},{"output_type":"stream","name":"stderr","text":["Validation Epoch 1: 100%|██████████| 13/13 [00:01<00:00,  9.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.00      0.00      0.00       109\n","     Neutral       0.62      0.61      0.61       223\n","    Positive       0.26      0.15      0.19       115\n","\n","   micro avg       0.54      0.34      0.42       447\n","   macro avg       0.29      0.25      0.27       447\n","weighted avg       0.38      0.34      0.35       447\n","\n","\n","===== EPOCH 2 =====\n","Epoch 2: Train loss = 7.0803\n"]},{"output_type":"stream","name":"stderr","text":["Validation Epoch 2: 100%|██████████| 13/13 [00:01<00:00,  9.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.56      0.14      0.22       109\n","     Neutral       0.78      0.73      0.76       223\n","    Positive       0.51      0.47      0.49       115\n","\n","   micro avg       0.68      0.52      0.59       447\n","   macro avg       0.62      0.45      0.49       447\n","weighted avg       0.66      0.52      0.56       447\n","\n","\n","===== EPOCH 3 =====\n","Epoch 3: Train loss = 5.2540\n"]},{"output_type":"stream","name":"stderr","text":["Validation Epoch 3: 100%|██████████| 13/13 [00:01<00:00,  8.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.49      0.51      0.50       109\n","     Neutral       0.83      0.83      0.83       223\n","    Positive       0.61      0.22      0.32       115\n","\n","   micro avg       0.70      0.59      0.64       447\n","   macro avg       0.64      0.52      0.55       447\n","weighted avg       0.69      0.59      0.62       447\n","\n","\n","===== EPOCH 4 =====\n","Epoch 4: Train loss = 3.9757\n"]},{"output_type":"stream","name":"stderr","text":["Validation Epoch 4: 100%|██████████| 13/13 [00:01<00:00,  8.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.69      0.48      0.57       109\n","     Neutral       0.87      0.81      0.84       223\n","    Positive       0.68      0.50      0.57       115\n","\n","   micro avg       0.79      0.65      0.71       447\n","   macro avg       0.75      0.59      0.66       447\n","weighted avg       0.78      0.65      0.71       447\n","\n","\n","===== EPOCH 5 =====\n","Epoch 5: Train loss = 2.6554\n"]},{"output_type":"stream","name":"stderr","text":["Validation Epoch 5: 100%|██████████| 13/13 [00:01<00:00,  9.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.75      0.79      0.77       109\n","     Neutral       0.90      0.71      0.79       223\n","    Positive       0.80      0.71      0.75       115\n","\n","   micro avg       0.83      0.73      0.78       447\n","   macro avg       0.82      0.74      0.77       447\n","weighted avg       0.84      0.73      0.78       447\n","\n","\n","===== EPOCH 6 =====\n","Epoch 6: Train loss = 1.7441\n"]},{"output_type":"stream","name":"stderr","text":["Validation Epoch 6: 100%|██████████| 13/13 [00:01<00:00,  9.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.75      0.90      0.82       109\n","     Neutral       0.91      0.74      0.82       223\n","    Positive       0.85      0.81      0.83       115\n","\n","   micro avg       0.85      0.80      0.82       447\n","   macro avg       0.84      0.82      0.82       447\n","weighted avg       0.86      0.80      0.82       447\n","\n","\n","===== EPOCH 7 =====\n","Epoch 7: Train loss = 1.2514\n"]},{"output_type":"stream","name":"stderr","text":["Validation Epoch 7: 100%|██████████| 13/13 [00:01<00:00,  8.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.80      0.93      0.86       109\n","     Neutral       0.92      0.69      0.78       223\n","    Positive       0.74      0.88      0.80       115\n","\n","   micro avg       0.83      0.79      0.81       447\n","   macro avg       0.82      0.83      0.82       447\n","weighted avg       0.84      0.79      0.81       447\n","\n","\n","===== EPOCH 8 =====\n","Epoch 8: Train loss = 0.9836\n"]},{"output_type":"stream","name":"stderr","text":["Validation Epoch 8: 100%|██████████| 13/13 [00:01<00:00,  8.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.82      0.93      0.87       109\n","     Neutral       0.91      0.75      0.82       223\n","    Positive       0.80      0.89      0.84       115\n","\n","   micro avg       0.85      0.83      0.84       447\n","   macro avg       0.84      0.85      0.84       447\n","weighted avg       0.86      0.83      0.84       447\n","\n","\n","===== EPOCH 9 =====\n","Epoch 9: Train loss = 0.8728\n"]},{"output_type":"stream","name":"stderr","text":["Validation Epoch 9: 100%|██████████| 13/13 [00:01<00:00,  8.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.82      0.94      0.87       109\n","     Neutral       0.91      0.77      0.83       223\n","    Positive       0.82      0.86      0.84       115\n","\n","   micro avg       0.86      0.83      0.85       447\n","   macro avg       0.85      0.85      0.85       447\n","weighted avg       0.87      0.83      0.85       447\n","\n","\n","===== EPOCH 10 =====\n","Epoch 10: Train loss = 0.7949\n"]},{"output_type":"stream","name":"stderr","text":["Validation Epoch 10: 100%|██████████| 13/13 [00:01<00:00,  9.02it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.82      0.94      0.87       109\n","     Neutral       0.91      0.77      0.83       223\n","    Positive       0.82      0.86      0.84       115\n","\n","   micro avg       0.86      0.83      0.85       447\n","   macro avg       0.85      0.85      0.85       447\n","weighted avg       0.87      0.83      0.85       447\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["NUM_EPOCHS = 10\n","\n","for epoch in range(NUM_EPOCHS):\n","    print(f\"\\n===== EPOCH {epoch+1} =====\")\n","    train_epoch(epoch, model, train_loader, optimizer, scheduler, device)\n","    valid_epoch(epoch, model, val_loader, device, label_set)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11696925,"status":"ok","timestamp":1746217058458,"user":{"displayName":"Lily Weaver","userId":"06185414616501025842"},"user_tz":240},"id":"glBR2yQLroVM","outputId":"22c9bd27-84c9-461f-c5c0-f627ed002a85"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","===== EPOCH 1 =====\n","Epoch 1: Train loss = 67.1443\n"]},{"name":"stderr","output_type":"stream","text":["Validation Epoch 1: 100%|██████████| 13/13 [01:22<00:00,  6.35s/it]\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.00      0.00      0.00        93\n","     Neutral       0.40      0.04      0.07       213\n","    Positive       0.00      0.00      0.00        90\n","\n","   micro avg       0.40      0.02      0.04       396\n","   macro avg       0.13      0.01      0.02       396\n","weighted avg       0.22      0.02      0.04       396\n","\n","\n","===== EPOCH 2 =====\n","Epoch 2: Train loss = 12.4641\n"]},{"name":"stderr","output_type":"stream","text":["Validation Epoch 2: 100%|██████████| 13/13 [01:20<00:00,  6.22s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.00      0.00      0.00        93\n","     Neutral       0.67      0.78      0.72       213\n","    Positive       0.55      0.46      0.50        90\n","\n","   micro avg       0.64      0.53      0.58       396\n","   macro avg       0.40      0.41      0.41       396\n","weighted avg       0.48      0.53      0.50       396\n","\n","\n","===== EPOCH 3 =====\n","Epoch 3: Train loss = 6.9002\n"]},{"name":"stderr","output_type":"stream","text":["Validation Epoch 3: 100%|██████████| 13/13 [01:24<00:00,  6.47s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.42      0.27      0.33        93\n","     Neutral       0.81      0.81      0.81       213\n","    Positive       0.50      0.07      0.12        90\n","\n","   micro avg       0.71      0.52      0.60       396\n","   macro avg       0.58      0.38      0.42       396\n","weighted avg       0.65      0.52      0.54       396\n","\n","\n","===== EPOCH 4 =====\n","Epoch 4: Train loss = 5.0852\n"]},{"name":"stderr","output_type":"stream","text":["Validation Epoch 4: 100%|██████████| 13/13 [01:21<00:00,  6.24s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.48      0.34      0.40        93\n","     Neutral       0.80      0.94      0.86       213\n","    Positive       0.50      0.03      0.06        90\n","\n","   micro avg       0.73      0.59      0.65       396\n","   macro avg       0.59      0.44      0.44       396\n","weighted avg       0.66      0.59      0.57       396\n","\n","\n","===== EPOCH 5 =====\n","Epoch 5: Train loss = 3.9643\n"]},{"name":"stderr","output_type":"stream","text":["Validation Epoch 5: 100%|██████████| 13/13 [01:22<00:00,  6.36s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.42      0.42      0.42        93\n","     Neutral       0.86      0.91      0.88       213\n","    Positive       0.36      0.18      0.24        90\n","\n","   micro avg       0.69      0.63      0.65       396\n","   macro avg       0.55      0.50      0.51       396\n","weighted avg       0.64      0.63      0.63       396\n","\n","\n","===== EPOCH 6 =====\n","Epoch 6: Train loss = 2.9161\n"]},{"name":"stderr","output_type":"stream","text":["Validation Epoch 6: 100%|██████████| 13/13 [01:20<00:00,  6.21s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.81      0.71      0.76        93\n","     Neutral       0.88      0.88      0.88       213\n","    Positive       0.86      0.84      0.85        90\n","\n","   micro avg       0.86      0.83      0.85       396\n","   macro avg       0.85      0.81      0.83       396\n","weighted avg       0.86      0.83      0.85       396\n","\n","\n","===== EPOCH 7 =====\n","Epoch 7: Train loss = 1.5265\n"]},{"name":"stderr","output_type":"stream","text":["Validation Epoch 7: 100%|██████████| 13/13 [01:22<00:00,  6.31s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.83      0.76      0.79        93\n","     Neutral       0.89      0.89      0.89       213\n","    Positive       0.85      0.86      0.85        90\n","\n","   micro avg       0.86      0.85      0.86       396\n","   macro avg       0.85      0.84      0.84       396\n","weighted avg       0.86      0.85      0.86       396\n","\n","\n","===== EPOCH 8 =====\n","Epoch 8: Train loss = 1.1787\n"]},{"name":"stderr","output_type":"stream","text":["Validation Epoch 8: 100%|██████████| 13/13 [01:21<00:00,  6.27s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.88      0.76      0.82        93\n","     Neutral       0.88      0.92      0.90       213\n","    Positive       0.90      0.82      0.86        90\n","\n","   micro avg       0.89      0.86      0.87       396\n","   macro avg       0.89      0.84      0.86       396\n","weighted avg       0.89      0.86      0.87       396\n","\n","\n","===== EPOCH 9 =====\n","Epoch 9: Train loss = 0.8992\n"]},{"name":"stderr","output_type":"stream","text":["Validation Epoch 9: 100%|██████████| 13/13 [01:20<00:00,  6.22s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.88      0.75      0.81        93\n","     Neutral       0.89      0.92      0.91       213\n","    Positive       0.82      0.83      0.82        90\n","\n","   micro avg       0.87      0.86      0.87       396\n","   macro avg       0.86      0.84      0.85       396\n","weighted avg       0.87      0.86      0.86       396\n","\n","\n","===== EPOCH 10 =====\n","Epoch 10: Train loss = 0.7133\n"]},{"name":"stderr","output_type":"stream","text":["Validation Epoch 10: 100%|██████████| 13/13 [01:20<00:00,  6.23s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","    Negative       0.85      0.78      0.82        93\n","     Neutral       0.88      0.91      0.90       213\n","    Positive       0.88      0.83      0.86        90\n","\n","   micro avg       0.87      0.86      0.87       396\n","   macro avg       0.87      0.84      0.86       396\n","weighted avg       0.87      0.86      0.87       396\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# ROBERTA OUTPUT"]},{"cell_type":"code","source":["import pickle\n","\n","with open('model_roberta_crf', 'wb') as f:\n","    pickle.dump(model, f)"],"metadata":{"id":"uEU6sf-qSG7B"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1FbEMpB-l2Pw4iMVxn_Nm--A5fnI5ChA1","timestamp":1744311836925}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}