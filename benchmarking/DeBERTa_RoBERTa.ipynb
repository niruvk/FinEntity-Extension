{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":21921,"status":"ok","timestamp":1746228852602,"user":{"displayName":"Lily Weaver","userId":"06185414616501025842"},"user_tz":240},"id":"iUgqPilfbtY-","outputId":"db6986b9-4283-4092-dd84-aa8d016d91a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'FinEntity' already exists and is not an empty directory.\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n","Requirement already satisfied: sequence-aligner in /usr/local/lib/python3.11/dist-packages (0.0.2)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.11/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (2.0.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.6.1)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n"]}],"source":["# ======================= SETUP =======================\n","!git clone https://github.com/yixuantt/FinEntity.git\n","!pip install transformers sequence-aligner evaluate\n","!pip install seqeval\n","\n","import json\n","import warnings\n","import numpy as np\n","import torch\n","from torch.utils.data import DataLoader, random_split\n","from torch import cuda\n","from transformers import (\n","    AutoTokenizer, AutoModelForTokenClassification,\n","    get_linear_schedule_with_warmup\n",")\n","from torch.optim import AdamW\n","from FinEntity.sequence_aligner.labelset import LabelSet\n","from FinEntity.sequence_aligner.dataset import TrainingDataset\n","from FinEntity.sequence_aligner.containers import TraingingBatch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cT1oPltJcD94"},"outputs":[],"source":["# ======================= LOAD DATA =======================\n","raw = json.load(open('FinEntity/data/FinEntity.json'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1003,"status":"ok","timestamp":1746228858786,"user":{"displayName":"Lily Weaver","userId":"06185414616501025842"},"user_tz":240},"id":"7k0smMmfcHwN","outputId":"039f126c-9387-4c95-c631-bc7dd1f75abc","collapsed":true},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["# ======================= CHOOSE MODEL =======================\n","# Choose ONE of the following model names:\n","# model_name = \"bert-base-cased\"\n","# model_name = \"roberta-base\"\n","# model_name = \"microsoft/deberta-base\"\n","\n","model_name = \"microsoft/deberta-base\"  # <<<<<<<<<<<< switch here\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1357,"status":"ok","timestamp":1746228865104,"user":{"displayName":"Lily Weaver","userId":"06185414616501025842"},"user_tz":240},"id":"LQRKNb2acNo_","outputId":"fe7b045c-662b-47a8-9504-6386d833f17c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Label mapping: {0: 'O', 1: 'B-Neutral', 2: 'I-Neutral', 3: 'L-Neutral', 4: 'U-Neutral', 5: 'B-Positive', 6: 'I-Positive', 7: 'L-Positive', 8: 'U-Positive', 9: 'B-Negative', 10: 'I-Negative', 11: 'L-Negative', 12: 'U-Negative'}\n"]}],"source":["# ======================= SETUP LABELS =======================\n","label_set = LabelSet(labels=[\"Neutral\", \"Positive\", \"Negative\"])\n","print(\"Label mapping:\", label_set.ids_to_label)\n","dataset = TrainingDataset(\n","    data=raw,\n","    tokenizer=tokenizer,\n","    label_set=label_set,\n","    tokens_per_batch=128\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BaK2Kzr5cTEQ"},"outputs":[],"source":["# ======================= TRAIN/VAL SPLIT =======================\n","train_size = int(0.8 * len(dataset))\n","validate_size = len(dataset) - train_size\n","train_dataset, validate_dataset = random_split(dataset, [train_size, validate_size])\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, collate_fn=TraingingBatch, shuffle=True)\n","val_loader = DataLoader(validate_dataset, batch_size=16, collate_fn=TraingingBatch, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11685,"status":"ok","timestamp":1746228880353,"user":{"displayName":"Lily Weaver","userId":"06185414616501025842"},"user_tz":240},"id":"gp_aHwU_cUXv","outputId":"960b7841-4e49-4bec-b83e-86ec2f0c265a","collapsed":true},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of DebertaForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["DebertaForTokenClassification(\n","  (deberta): DebertaModel(\n","    (embeddings): DebertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n","      (LayerNorm): DebertaLayerNorm()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): DebertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x DebertaLayer(\n","          (attention): DebertaAttention(\n","            (self): DisentangledSelfAttention(\n","              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n","              (pos_dropout): Dropout(p=0.1, inplace=False)\n","              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n","              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): DebertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): DebertaLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): DebertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): DebertaLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (rel_embeddings): Embedding(1024, 768)\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=13, bias=True)\n",")"]},"metadata":{},"execution_count":7}],"source":["# ======================= MODEL INIT =======================\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_name,\n","    num_labels=len(label_set.ids_to_label.values())\n",")\n","\n","device = 'cuda:0' if cuda.is_available() else 'cpu'\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m5wuGS9Zcawi"},"outputs":[],"source":["# ======================= TRAINING CONFIG =======================\n","t_total = len(train_loader) * 10  # 10 epochs\n","weight_decay = 0.01\n","learning_rate = 3e-5\n","warmup_ratio = 0.1\n","\n","no_decay = [\"bias\", \"LayerNorm.weight\"]\n","optimizer_grouped_parameters = [\n","    {\n","        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","        \"weight_decay\": weight_decay,\n","    },\n","    {\n","        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","        \"weight_decay\": 0.0,\n","    },\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=1e-6)\n","warmup_steps = int(t_total * warmup_ratio)\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qzpc1AYpco6a"},"outputs":[],"source":["# ======================= TRAINING FUNCTIONS =======================\n","def train_epoch(model, loader, optimizer, scheduler, device):\n","    model.train()\n","    total_loss = 0\n","    for batch in loader:\n","        optimizer.zero_grad()\n","        input_ids = batch.input_ids.to(device)\n","        attention_mask = batch.attention_masks.to(device)\n","        labels = batch.labels.to(device)\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        loss.backward()\n","        total_loss += loss.item()\n","        optimizer.step()\n","        scheduler.step()\n","    return total_loss / len(loader)\n","\n","\n","from seqeval.metrics import classification_report\n","from seqeval.scheme import BILOU\n","from tqdm import tqdm\n","\n","def valid_epoch(e, model, loader, device, label_set):\n","    model.eval()\n","    preds_all, labels_all = [], []\n","    with torch.no_grad():\n","        for batch in tqdm(loader, desc=f\"Validation Epoch {e+1}\"):\n","            input_ids = batch.input_ids.to(device)\n","            attention_mask = batch.attention_masks.to(device)\n","            labels = batch.labels.to(device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","            preds = torch.argmax(logits, dim=-1)\n","\n","            # Loop over batch\n","            for i in range(labels.size(0)):\n","                pred_seq = []\n","                label_seq = []\n","                for j in range(labels.size(1)):\n","                    if labels[i, j] != -100:\n","                        pred_seq.append(label_set.ids_to_label[preds[i, j].item()])\n","                        label_seq.append(label_set.ids_to_label[labels[i, j].item()])\n","                preds_all.append(pred_seq)\n","                labels_all.append(label_seq)\n","\n","    print(\"\\nValidation Report:\")\n","    print(classification_report(labels_all, preds_all, mode='strict', scheme=BILOU))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05aJUKnFcp_5","outputId":"d3f4b830-5e25-4a6a-b851-9851eedd518e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","===== EPOCH 1/10 =====\n"]}],"source":["# ======================= TRAIN LOOP =======================\n","warnings.filterwarnings('ignore')\n","\n","EPOCHS = 10\n","for epoch in range(EPOCHS):\n","    print(f\"\\n===== EPOCH {epoch+1}/{EPOCHS} =====\")\n","    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n","    print(\"Train loss:\", train_loss)\n","    valid_epoch(epoch, model, val_loader, device, label_set)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1FbEMpB-l2Pw4iMVxn_Nm--A5fnI5ChA1","timestamp":1744154355375}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}