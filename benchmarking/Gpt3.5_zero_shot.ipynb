{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U seqeval"
      ],
      "metadata": {
        "id": "5Tpr-OxF38n9"
      },
      "id": "5Tpr-OxF38n9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import json"
      ],
      "metadata": {
        "id": "v6U2WdfEqRA9"
      },
      "id": "v6U2WdfEqRA9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_json(\"hf://datasets/yixuantt/FinEntity/FinEntity.json\")"
      ],
      "metadata": {
        "id": "s-t1CjWmqp_d"
      },
      "id": "s-t1CjWmqp_d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_str = df.to_json(orient='records')"
      ],
      "metadata": {
        "id": "KC3Cok2rsa35"
      },
      "id": "KC3Cok2rsa35",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw = json.loads(json_str)"
      ],
      "metadata": {
        "id": "j7xqXW5es27u"
      },
      "id": "j7xqXW5es27u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "openai_api = userdata.get('openai_api')"
      ],
      "metadata": {
        "id": "Hz6J_myHhdrQ"
      },
      "id": "Hz6J_myHhdrQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a48ad357-b3fd-4609-a4ea-5dd94da1560d",
      "metadata": {
        "id": "a48ad357-b3fd-4609-a4ea-5dd94da1560d"
      },
      "outputs": [],
      "source": [
        "# raw = json.load(open('./data/FinEntity.json'))\n",
        "raw = raw[:200]\n",
        "openai.api_key = openai_api\n",
        "\n",
        "sys_prompt = \"Discard all the previous instructions. Behave like you are an expert entity recognizer and sentiment classifier. \"\n",
        "user_prompt = \"\"\"\n",
        "Identify the entities which are companies or organizations from the following content and classify the sentiment of the corresponding entities into ‘Neutral’, ‘Positive’, or ‘Negative’ classes.\n",
        "Considering every sentence as a String in python, provide the entities with the start and end index to mark the boundaries of it including spaces and punctuation using zero-based indexing.\n",
        "Do not give explanations for the sentiment. In the output, tag means sentiment; value means entity name. If no entity is found in the sentence, the response should be empty.\n",
        "Only use new lines between outputs for each entity.\n",
        "The sentence:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3a96169-0419-4e8d-b207-4383e720fb44",
      "metadata": {
        "tags": [],
        "id": "d3a96169-0419-4e8d-b207-4383e720fb44"
      },
      "outputs": [],
      "source": [
        "def subset(alist, idxs):\n",
        "    sub_list = []\n",
        "    for idx in idxs:\n",
        "        sub_list.append(alist[idx])\n",
        "\n",
        "    return sub_list\n",
        "\n",
        "import time\n",
        "result_list=[]\n",
        "compare_list=[]\n",
        "for item in raw:\n",
        "    sentence = item['content']\n",
        "    #sentence ='Nearly all major S&P 500 sectors are red, with materials <.SPLRCM> and communications services <.SPLRCL> taking the biggest hits. Staples <.SPLRCS> and healthcare <.SPXHC> are posting small gains.'\n",
        "    try:\n",
        "        rsp = openai.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo-0125\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": sys_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt + sentence}\n",
        "            ],\n",
        "            temperature=0.0,\n",
        "        )\n",
        "    except:\n",
        "        print(\"retry request\")\n",
        "        time.sleep(0.5)\n",
        "        rsp = openai.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo-0125\",\n",
        "            messages=[{\"role\": \"user\", \"content\": sentence},],temperature=0.0,)\n",
        "    else:\n",
        "        result_dict = {}\n",
        "        result_dict['content'] = sentence\n",
        "        if len(rsp.choices)==0:\n",
        "            result_dict['annotations'] = []\n",
        "            result_list.append(result_dict)\n",
        "            compare_list.append(item)\n",
        "            continue\n",
        "        choice = rsp.choices[0]\n",
        "        message = choice.message\n",
        "        res_str = message.content\n",
        "        res_str = res_str.split('\\n```')\n",
        "        anno_list = []\n",
        "        if len(res_str)==0:\n",
        "            result_dict['annotations'] = []\n",
        "            result_list.append(result_dict)\n",
        "            compare_list.append(item)\n",
        "            continue\n",
        "        for res in res_str:\n",
        "            index_left = res.find('{')\n",
        "            index_right = res.find('}')\n",
        "            if index_right == -1 or index_left == -1:\n",
        "                continue\n",
        "            res = res[index_left:index_right+1]\n",
        "            sub_json = json.loads(res)\n",
        "            anno_list.append(sub_json)\n",
        "        result_dict['annotations'] = anno_list\n",
        "        result_list.append(result_dict)\n",
        "        compare_list.append(item)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Correcting start and end tags\n",
        "for i,item in enumerate(result_list):\n",
        "    text = item['content']\n",
        "    annos = item['annotations']\n",
        "    try:\n",
        "      sorted_annos = sorted(annos, key=lambda x: x['start'])\n",
        "    except:\n",
        "      continue\n",
        "    value_list = []\n",
        "    start_list = []\n",
        "    drop_list = []\n",
        "    for indx,sub_annos in enumerate(sorted_annos):\n",
        "        value = sub_annos['value']\n",
        "        if value not in value_list:\n",
        "            start = text.find(value)\n",
        "        else:\n",
        "            index_list = []\n",
        "            for j,v in enumerate(value_list):\n",
        "                if v==value:\n",
        "                    index_list.append(j)\n",
        "            sub_start = subset(start_list,index_list)\n",
        "            last_start = max(sub_start)\n",
        "            start = text.find(value,last_start+1)\n",
        "        sub_annos['start'] = start\n",
        "        sub_annos['end'] = start + len(value)\n",
        "        value_list.append(value)\n",
        "        start_list.append(start)"
      ],
      "metadata": {
        "id": "1SY_ppyCt09P"
      },
      "id": "1SY_ppyCt09P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "879dae4d-cf4b-4df3-9475-142eb5f9487d",
      "metadata": {
        "id": "879dae4d-cf4b-4df3-9475-142eb5f9487d"
      },
      "outputs": [],
      "source": [
        "with open('/content/open_ai.json', 'wt') as f:\n",
        "    print(json.dumps(result_list), file=f)\n",
        "print(\"COMPLETE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19de4429-2560-4518-8da6-65ebf5cb242a",
      "metadata": {
        "id": "19de4429-2560-4518-8da6-65ebf5cb242a"
      },
      "outputs": [],
      "source": [
        "print(len(compare_list))\n",
        "print(len(result_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4baed6ee-4bd9-479b-b11b-88274ca6f110",
      "metadata": {
        "id": "4baed6ee-4bd9-479b-b11b-88274ca6f110"
      },
      "outputs": [],
      "source": [
        "for idx,item in enumerate(result_list):\n",
        "    annos = item['annotations']\n",
        "    drop_list=[]\n",
        "    try:\n",
        "      item['annotations'] = [x for x in annos if x['start']>0]\n",
        "    except:\n",
        "      item['annotations'] = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15721aed-89da-4ef5-b2fa-2542f57d6755",
      "metadata": {
        "id": "15721aed-89da-4ef5-b2fa-2542f57d6755"
      },
      "outputs": [],
      "source": [
        "for idx,item in enumerate(result_list):\n",
        "    annos = item['annotations']\n",
        "    for a in annos:\n",
        "        if a['start']<0:\n",
        "            print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0509423-361d-4abe-9006-1b4f37c660eb",
      "metadata": {
        "id": "c0509423-361d-4abe-9006-1b4f37c660eb"
      },
      "outputs": [],
      "source": [
        "#result_list = json.load(open('./data/open_ai.json'))\n",
        "for example in result_list:\n",
        "    for annotation in example['annotations']:\n",
        "        #We expect the key of label to be label but the data has tag\n",
        "        ## because we are doing zero shot (provide no examples),\n",
        "        ## the output format is slightly different (eg. in capitalization)\n",
        "        ## from few-shot\n",
        "        annotation['label'] = annotation['tag']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qjl_qa3-y4t4"
      },
      "id": "qjl_qa3-y4t4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Courses/Spring 2025/COS 484/final project/chae')"
      ],
      "metadata": {
        "id": "nL4-16fUzFaB"
      },
      "id": "nL4-16fUzFaB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a4dd26b-fc86-4552-8209-3d862e30188e",
      "metadata": {
        "id": "9a4dd26b-fc86-4552-8209-3d862e30188e"
      },
      "outputs": [],
      "source": [
        "from sequence_aligner.labelset import LabelSet\n",
        "from sequence_aligner.dataset import TrainingDatasetCRF\n",
        "from sequence_aligner.containers import TraingingBatch\n",
        "from transformers import BertTokenizerFast"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('yiyanghkust/finbert-pretrain')\n",
        "label_set = LabelSet(labels=[\"Neutral\", \"Positive\", \"Negative\"])  # label in this dataset\n",
        "\n",
        "dataset = TrainingDatasetCRF(data=compare_list, tokenizer=tokenizer, label_set=label_set,tokens_per_batch = 128)\n",
        "dataset_openai = TrainingDatasetCRF(data=result_list, tokenizer=tokenizer, label_set=label_set,tokens_per_batch = 128)"
      ],
      "metadata": {
        "id": "kj26BRjD2uYR"
      },
      "id": "kj26BRjD2uYR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import f1_score\n",
        "from seqeval.metrics import precision_score\n",
        "from seqeval.metrics import accuracy_score\n",
        "from seqeval.metrics import recall_score\n",
        "from seqeval.metrics import classification_report\n",
        "from util.process import ids_to_labels,Metrics,Metrics_e\n",
        "from seqeval.scheme import BILOU"
      ],
      "metadata": {
        "id": "Adb0TmVx2xAC"
      },
      "id": "Adb0TmVx2xAC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f53fe786-4dfb-4cc1-a43d-85a237ca2371",
      "metadata": {
        "tags": [],
        "id": "f53fe786-4dfb-4cc1-a43d-85a237ca2371"
      },
      "outputs": [],
      "source": [
        "label_list=[]\n",
        "pred_label_list=[]\n",
        "for i in range(len(dataset)):\n",
        "    sub_list=[]\n",
        "    pred_sub_list=[]\n",
        "    for m in dataset[i].labels:\n",
        "        if m == -1:\n",
        "            continue\n",
        "        else:\n",
        "            sub_list.append(label_set.ids_to_label[m])\n",
        "    for n in dataset_openai[i].labels:\n",
        "        if n == -1:\n",
        "            continue\n",
        "        else:\n",
        "            if n == None:\n",
        "                n = 0\n",
        "            pred_sub_list.append(label_set.ids_to_label[n])\n",
        "    label_list.append(sub_list)\n",
        "    pred_label_list.append(pred_sub_list)\n",
        "report=classification_report(label_list, pred_label_list, mode='strict', scheme=BILOU)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b999267-5271-472c-ae0b-c3ec77dbeb5c",
      "metadata": {
        "id": "8b999267-5271-472c-ae0b-c3ec77dbeb5c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9d19d2b-8a58-453e-b9da-8d3cdbf8593d",
      "metadata": {
        "id": "c9d19d2b-8a58-453e-b9da-8d3cdbf8593d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}